{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = './Data/genres_original/blues/blues.00000.wav'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "\n",
    "# Load a .wav file using librosa\n",
    "data, sr = librosa.load(data_path) # Sampling rate = 22050"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Playing audio file\n",
    "import IPython\n",
    "\n",
    "IPython.display.Audio(data,rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Wave form of the audio\n",
    "plt.figure(figsize=(12,6))\n",
    "librosa.display.waveshow(data, color=\"#2B4F72\", alpha = 0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import pandas as pd\n",
    "\n",
    "num_segment=10\n",
    "num_mfcc=20\n",
    "sample_rate=22050\n",
    "n_fft=2048\n",
    "hop_length=512\n",
    "\n",
    "my_csv={\"filename\":[], \"chroma_stft_mean\": [], \"chroma_stft_var\": [], \"rms_mean\": [], \"rms_var\": [], \"spectral_centroid_mean\": [],\n",
    "        \"spectral_centroid_var\": [], \"spectral_bandwidth_mean\": [], \"spectral_bandwidth_var\": [], \"rolloff_mean\": [], \"rolloff_var\": [],\n",
    "        \"zero_crossing_rate_mean\": [], \"zero_crossing_rate_var\": [], \"harmony_mean\": [], \"harmony_var\": [], \"perceptr_mean\": [],\n",
    "        \"perceptr_var\": [], \"tempo\": [], \"mfcc1_mean\": [], \"mfcc1_var\" : [], \"mfcc2_mean\" : [], \"mfcc2_var\" : [],\n",
    "        \"mfcc3_mean\" : [], \"mfcc3_var\" : [], \"mfcc4_mean\" : [], \"mfcc4_var\" : [], \"mfcc5_mean\" : [],\n",
    "        \"mfcc5_var\" : [], \"mfcc6_mean\" : [], \"mfcc6_var\" : [], \"mfcc7_mean\" : [], \"mfcc7_var\" : [],\n",
    "        \"mfcc8_mean\" : [], \"mfcc8_var\" : [], \"mfcc9_mean\" : [], \"mfcc9_var\" : [], \"mfcc10_mean\" : [],\n",
    "        \"mfcc10_var\" : [], \"mfcc11_mean\" : [], \"mfcc11_var\" : [], \"mfcc12_mean\" : [], \"mfcc12_var\" : [],\n",
    "        \"mfcc13_mean\" : [], \"mfcc13_var\" : [], \"mfcc14_mean\" : [], \"mfcc14_var\" : [], \"mfcc15_mean\" : [],\n",
    "        \"mfcc15_var\" : [], \"mfcc16_mean\" : [], \"mfcc16_var\" : [], \"mfcc17_mean\" : [], \"mfcc17_var\" : [],\n",
    "        \"mfcc18_mean\" : [], \"mfcc18_var\" : [], \"mfcc19_mean\" : [], \"mfcc19_var\" : [], \"mfcc20_mean\" : [],\n",
    "        \"mfcc20_var\":[], \"label\":[]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path=\"./Data/genres_original/\"\n",
    "audio_files = glob(dataset_path + \"/*/*\")\n",
    "# genre = glob(dataset_path + \"/*\")\n",
    "# n_genres=len(genre)\n",
    "# genre=[genre[x].split('/')[-1] for x in range(n_genres)]\n",
    "# print(genre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_per_segment = int(sample_rate*30/num_segment)\n",
    "\n",
    "genre=\"\"\n",
    "for f in sorted(audio_files):\n",
    "    if genre!=f.split('/')[-2]:\n",
    "        genre=f.split('/')[-2]\n",
    "        print(\"Processsing \" + genre + \"...\")\n",
    "    fname=f.split('/')[-1]\n",
    "    try:\n",
    "        y, sr = librosa.load(f, sr=sample_rate)\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "    for n in range(num_segment):\n",
    "        y_seg = y[samples_per_segment*n: samples_per_segment*(n+1)]\n",
    "        #Chromagram\n",
    "        chroma_hop_length = 512\n",
    "        chromagram = librosa.feature.chroma_stft(y=y_seg, sr=sample_rate, hop_length=chroma_hop_length)\n",
    "        my_csv[\"chroma_stft_mean\"].append(chromagram.mean())\n",
    "        my_csv[\"chroma_stft_var\"].append(chromagram.var())\n",
    "\n",
    "        #Root Mean Square Energy\n",
    "        RMSEn= librosa.feature.rms(y=y_seg)\n",
    "        my_csv[\"rms_mean\"].append(RMSEn.mean())\n",
    "        my_csv[\"rms_var\"].append(RMSEn.var())\n",
    "\n",
    "        #Spectral Centroid\n",
    "        spec_cent=librosa.feature.spectral_centroid(y=y_seg)\n",
    "        my_csv[\"spectral_centroid_mean\"].append(spec_cent.mean())\n",
    "        my_csv[\"spectral_centroid_var\"].append(spec_cent.var())\n",
    "\n",
    "        #Spectral Bandwith\n",
    "        spec_band=librosa.feature.spectral_bandwidth(y=y_seg,sr=sample_rate)\n",
    "        my_csv[\"spectral_bandwidth_mean\"].append(spec_band.mean())\n",
    "        my_csv[\"spectral_bandwidth_var\"].append(spec_band.var())\n",
    "\n",
    "        #Rolloff\n",
    "        spec_roll=librosa.feature.spectral_rolloff(y=y_seg,sr=sample_rate)\n",
    "        my_csv[\"rolloff_mean\"].append(spec_roll.mean())\n",
    "        my_csv[\"rolloff_var\"].append(spec_roll.var())\n",
    "\n",
    "        #Zero Crossing Rate\n",
    "        zero_crossing=librosa.feature.zero_crossing_rate(y=y_seg)\n",
    "        my_csv[\"zero_crossing_rate_mean\"].append(zero_crossing.mean())\n",
    "        my_csv[\"zero_crossing_rate_var\"].append(zero_crossing.var())\n",
    "\n",
    "        #Harmonics and Perceptrual\n",
    "        harmony, perceptr = librosa.effects.hpss(y=y_seg)\n",
    "        my_csv[\"harmony_mean\"].append(harmony.mean())\n",
    "        my_csv[\"harmony_var\"].append(harmony.var())\n",
    "        my_csv[\"perceptr_mean\"].append(perceptr.mean())\n",
    "        my_csv[\"perceptr_var\"].append(perceptr.var())\n",
    "\n",
    "        #Tempo\n",
    "        tempo, _ = librosa.beat.beat_track(y=y_seg, sr=sample_rate)\n",
    "        my_csv[\"tempo\"].append(tempo)\n",
    "\n",
    "        #MFCC\n",
    "        mfcc=librosa.feature.mfcc(y=y_seg,sr=sample_rate, n_mfcc=num_mfcc, n_fft=n_fft, hop_length=hop_length)\n",
    "        mfcc=mfcc.T\n",
    "\n",
    "\n",
    "        fseg_name='.'.join(fname.split('.')[:2])+f'.{n}.wav'\n",
    "        my_csv[\"filename\"].append(fseg_name)\n",
    "        my_csv[\"label\"].append(genre)\n",
    "        for x in range(20):\n",
    "            feat1 = \"mfcc\" + str(x+1) + \"_mean\"\n",
    "            feat2 = \"mfcc\" + str(x+1) + \"_var\"\n",
    "            my_csv[feat1].append(mfcc[:,x].mean())\n",
    "            my_csv[feat2].append(mfcc[:,x].var())\n",
    "    print(fname)\n",
    "\n",
    "df = pd.DataFrame(my_csv)\n",
    "df.to_csv('/Data/features_3_sec.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the csv file\n",
    "df = pd.read_csv(\"./Data/features_3_sec.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shape of the data\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data type of the data\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the column filename as it is no longer required for training\n",
    "df=df.drop(labels=\"filename\",axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the column length as it is constant\n",
    "df=df.drop(labels=\"length\",axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y =  df.iloc[:,:-1], df.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Label Encoding - encod the categorical classes with numerical integer values for training\n",
    "\n",
    "# Blues - 0\n",
    "# Classical - 1\n",
    "# Country - 2\n",
    "# Disco - 3\n",
    "# Hip-hop - 4\n",
    "# Jazz - 5\n",
    "# Metal - 6\n",
    "# Pop - 7\n",
    "# Reggae - 8\n",
    "# Rock - 9\n",
    "\n",
    "encoder=LabelEncoder()\n",
    "y=encoder.fit_transform(y)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler=StandardScaler()\n",
    "X=scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# splitting 70% data into training set and the remaining 30% to test set\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3, random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test data size\n",
    "len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# size of training data\n",
    "len(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_cls=KNeighborsClassifier(n_neighbors=3)\n",
    "knn_cls.fit(X_train,y_train)\n",
    "y_pred=knn_cls.predict(X_test)\n",
    "\n",
    "print(\"Training set score: {:.3f}\".format(knn_cls.score(X_train, y_train)))\n",
    "print(\"Test set score: {:.3f}\".format(knn_cls.score(X_test, y_test)))\n",
    "\n",
    "cf_matrix = confusion_matrix(y_test, y_pred)\n",
    "sns.set(rc = {'figure.figsize':(12,6)})\n",
    "sns.heatmap(cf_matrix, annot=True)\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_cls = SVC(kernel='rbf', degree=8)\n",
    "svm_cls.fit(X_train, y_train)\n",
    "\n",
    "print(\"Training set score: {:.3f}\".format(svm_cls.score(X_train, y_train)))\n",
    "print(\"Test set score: {:.3f}\".format(svm_cls.score(X_test, y_test)))\n",
    "\n",
    "y_pred = svm_cls.predict(X_test)\n",
    "\n",
    "cf_matrix3 = confusion_matrix(y_test, y_pred)\n",
    "sns.set(rc = {'figure.figsize':(12,6)})\n",
    "sns.heatmap(cf_matrix3, annot=True)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feed-forward Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.functional import F\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(MLP, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(input_size, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, 128)\n",
    "        self.fc4 = nn.Linear(128, 64)\n",
    "        self.fc5 = nn.Linear(64, 32)\n",
    "        self.fc6 = nn.Linear(32, 10)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc4(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc5(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.softmax(self.fc6(x), dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = X_train.shape[1]\n",
    "model = MLP(input_size)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.000146)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 300\n",
    "batch_size = 256\n",
    "\n",
    "train_dataset = TensorDataset(torch.tensor(X_train), torch.tensor(y_train))\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "val_dataset = TensorDataset(torch.tensor(X_test), torch.tensor(y_test))\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "step = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for inputs, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs.float())\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if step % 100 ==0:\n",
    "          print(f\"Step {step}, Train Loss: {loss.item():.4f}\")\n",
    "        step += 1\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            outputs = model(inputs.float())\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "    val_loss /= len(val_loader)\n",
    "    val_accuracy = 100 * correct / total\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample testing\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    predictions = model(torch.tensor(X_test).float())\n",
    "    _, predicted_indices = predictions.max(1)\n",
    "    print(\"Expected Index: {}, Predicted Index: {}\".format(y_test, predicted_indices.numpy()))\n",
    "\n",
    "# Confusion Matrix and Classification Report\n",
    "from sklearn.metrics import classification_report\n",
    "import seaborn as sns\n",
    "\n",
    "y_pred = predicted_indices.numpy()\n",
    "cf_matrix = confusion_matrix(y_test, y_pred)\n",
    "sns.set(rc={'figure.figsize':(12,6)})\n",
    "sns.heatmap(cf_matrix, annot=True)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
